default_model: "fuelix-gpt4o-mini"

models:
  - model_name: "fuelix-llama4-scout"
    model: "openai/llama-4-scout-17b-16e"

  - model_name: "fuelix-gpt4o-mini"
    model: "openai/gpt-4o-mini"

  # Groq (optional fallback)
  - model_name: "groq/llama-3.1-8b-instant"
    model: "groq/llama-3.1-8b-instant"

  # Optional: keep Ollama models for local testing (not used on Fly)
  - model_name: "ollama-mistral-nemo"
    model: "ollama/mistral-nemo"

  - model_name: "ollama-local-llama3"
    model: "ollama/llama3"

  - model_name: "ollama-local-mistral"
    model: "ollama/mistral"

  - model_name: "ollama-local-llava"
    model: "ollama/llava:7b"
