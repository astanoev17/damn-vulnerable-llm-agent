default_model: "openai/meta-llama/llama-3.1-8b-instruct"

models:
  - model_name: "openai/meta-llama/llama-3.1-8b-instruct"
    model: "openai/meta-llama/llama-3.1-8b-instruct"

  # Groq (optional fallback)
  - model_name: "groq/llama-3.1-8b-instant"
    model: "groq/llama-3.1-8b-instant"

  # Optional: keep Ollama models for local testing (not used on Fly)
  - model_name: "ollama-mistral-nemo"
    model: "ollama/mistral-nemo"

  - model_name: "ollama-local-llama3"
    model: "ollama/llama3"

  - model_name: "ollama-local-mistral"
    model: "ollama/mistral"

  - model_name: "ollama-local-llava"
    model: "ollama/llava:7b"
