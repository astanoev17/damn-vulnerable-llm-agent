default_model: "fuelix-llama-4-scout"

models:
  - model_name: "fuelix-llama-4-scout"
    model: "openai/llama-4-scout-17b-16e"

  # Optional: add a stronger one too
  - model_name: "fuelix-llama-4-maverick"
    model: "openai/llama-4-maverick-17b-128e"

  # Groq (optional fallback)
  - model_name: "groq/llama-3.1-8b-instant"
    model: "groq/llama-3.1-8b-instant"

  # Optional: keep Ollama models for local testing (not used on Fly)
  - model_name: "ollama-mistral-nemo"
    model: "ollama/mistral-nemo"

  - model_name: "ollama-local-llama3"
    model: "ollama/llama3"

  - model_name: "ollama-local-mistral"
    model: "ollama/mistral"

  - model_name: "ollama-local-llava"
    model: "ollama/llava:7b"
