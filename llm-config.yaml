default_model: "fuelix-llama-3-1-8b"

models:
  - model_name: "fuelix-llama-3-1-8b"
    model: "openai/meta-llama/llama-3.1-8b-instruct"
    
models:
  - model_name: "groq/llama-3.1-8b-instant"
    model: "groq/llama-3.1-8b-instant"

  # Optional: keep Ollama models for local testing (not used on Fly)
  - model_name: "ollama-mistral-nemo"
    model: "ollama/mistral-nemo"

  - model_name: "ollama-local-llama3"
    model: "ollama/llama3"

  - model_name: "ollama-local-mistral"
    model: "ollama/mistral"

  - model_name: "ollama-local-llava"
    model: "ollama/llava:7b"
